{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11856114",
   "metadata": {},
   "source": [
    "# Step1-DownloadSampleDataandSetupEnvironment\n",
    "\n",
    "\n",
    "## Download Anaconda\n",
    "\n",
    "To run the PRS Notebooks, set up a conda environment. Some tools require a dedicated (separate) conda environment, and for such tools, instructions are provided in their corresponding Notebooks.\n",
    "\n",
    "### Windows:\n",
    "1. Visit the [Anaconda website](https://www.anaconda.com/download).\n",
    "2. Choose the appropriate installer (64-bit is recommended for most systems).\n",
    "3. Run the installer and follow the on-screen instructions.\n",
    "\n",
    "### Linux:\n",
    "1. Open a terminal window and run these commands:\n",
    "    ```bash\n",
    "    wget https://repo.anaconda.com/archive/Anaconda3-2024.01-Linux-x86_64.sh\n",
    "    chmod +x Anaconda3-2024.01-Linux-x86_64.sh\n",
    "    bash Anaconda3-2024.01-Linux-x86_64.sh\n",
    "    source ~/.bashrc\n",
    "    ```\n",
    "\n",
    "### Create a Dedicated Environment for Your Project:\n",
    "\n",
    "1. Open a terminal window (or Anaconda Prompt on Windows).\n",
    "2. Create a new environment named \"prstools\" with Python 3.10:\n",
    "    ```bash\n",
    "    conda create -n prstools python=3.10\n",
    "    ```\n",
    "\n",
    "3. Activate the environment:\n",
    "    ```bash\n",
    "    conda activate prstools\n",
    "    ```\n",
    "\n",
    "### Install R within the Environment:\n",
    "\n",
    "Install R version 4.3.2 from the conda-forge channel:\n",
    "```bash\n",
    "conda install -c conda-forge r-base=4.3.2\n",
    "conda install -c conda-forge r-essentials\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e2a2b1",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "In this section, we will download the sample data.\n",
    "\n",
    "\n",
    "### Download Sample Data\n",
    "\n",
    "The first step is to download the sample data. You can find the base data [here](https://drive.google.com/file/d/1RWjk49QNZj9zvJHc9X_wyZ51fdy6xQjv/view) and the target data [here](https://drive.google.com/file/d/1uhJR_3sn7RA8U5iYQbcmTp6vFdQiF4F2/view).\n",
    "\n",
    "### Extracting Target Data\n",
    "\n",
    "Extract the target data and organize it with the following files in a directory named `SampleData1`:\n",
    "\n",
    "- `SampleData1.bed`: Plink Files (bed, bim, fam) containing genotype information.\n",
    "- `SampleData1.bim`\n",
    "- `SampleData1.fam`\n",
    "- `SampleData1.cov`: Contains covariate information.\n",
    "- `SampleData1.height`: Contains the actual height phenotype.\n",
    "- `SampleData1.gz`: GWAS summary statistic file.\n",
    "\n",
    "**Ensure to rename all files to the `SampleData1` prefix.**\n",
    "\n",
    "```\n",
    ".\n",
    "├── SampleData1\n",
    "│   ├── SampleData1.bed\n",
    "│   ├── SampleData1.bim\n",
    "│   ├── SampleData1.cov\n",
    "│   ├── SampleData1.fam\n",
    "│   ├── SampleData1.gz\n",
    "│   └── SampleData1.height\n",
    "```\n",
    "\n",
    "\n",
    "### View Bed Files\n",
    "\n",
    "To view Bed files, visit [Plink Binary Files Documentation](https://zzz.bwh.harvard.edu/plink/binary.shtml).\n",
    "\n",
    "\n",
    "### Analyzing Quantitative Trait (Height)\n",
    "\n",
    "We will begin by analyzing the quantitative trait (height). The dataset used for the continuous trait analysis is sourced from the tutorial by [choishingwan](https://choishingwan.github.io/PRS-Tutorial/base/), and we express our gratitude for making it publicly available.\n",
    "\n",
    "### Polygenic Risk Score (PRS) Tools Overview\n",
    "\n",
    "PRS tools can be categorized into three types:\n",
    "\n",
    "1. **Type 1: Summary Statistics File Only**\n",
    "   - These tools use a summary statistic file (e.g., gwas.txt) and estimate betas or posterior probabilities. They may require population-specific linkage disequilibrium calculations.\n",
    "\n",
    "2. **Type 2: Summary Statistic File and Individual Data Set**\n",
    "   - This category of PRS tools requires both a summary statistic file and an individual dataset. They optimize various hyperparameters for beta estimation or snp weight estimation.\n",
    "\n",
    "3. **Type 3: Individual Data Set Only**\n",
    "   - These tools focus on polygenic risk score calculation for individuals without relying on a summary statistic file. They incorporate linkage equilibrium for betas or snp weight estimation.\n",
    "\n",
    "4. **Type 4: Multi-ancestry/Disease Tools**\n",
    "   - These tools use GWAS from multiple populations or multiple diseases to calculate posterior probabilities or new Betas.\n",
    "\n",
    "\n",
    "\n",
    "### Data Splitting and Hyperparameter Optimization\n",
    "\n",
    "The target data is split into a 75% training or hyperparameter optimization set and a 25% testing set for final performance evaluation.\n",
    " \n",
    "For binary phenotypes, we used a stratified cross-validation technique to split the data. \n",
    "```python\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "```\n",
    "\n",
    "For continuous phenotypes, we used cross-validation to split the data into 5 folds. \n",
    "```python\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "```\n",
    " \n",
    "\n",
    "\n",
    "Hyperparameter optimization can be categorized into two types:\n",
    "\n",
    "1. **Genotype data Quality controls related Hyperparameters**\n",
    "   - This includes considerations such as pruning and clumping during quality controls on the target data.\n",
    "\n",
    "2. **Tools-Specific Hyperparameters**\n",
    "   - When using the GWAS File and an individual dataset, specific hyperparameters, such as lambdas for lasso, may be considered.\n",
    "\n",
    "\n",
    "### Full Credit to Shing Wan Choi\n",
    "\n",
    "- GitHub: [Shing Wan Choi](https://github.com/choishingwan)\n",
    "\n",
    "Tutorial Link from where the code has been inferred: [Shing Wan Choi's PRS Tutorial](https://choishingwan.github.io/PRS-Tutorial/base/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c359d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code is for Linux\n",
    "!conda config --add channels defaults\n",
    "!conda config --add channels bioconda\n",
    "!conda config --add channels conda-forge\n",
    "!conda install bioconda::bedtools\n",
    "!conda install bioconda::samtools\n",
    "# You can execute the code from terminal after activitating the conda environment.\n",
    "# conda activate genetics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417e4bbc",
   "metadata": {},
   "source": [
    "## View Data\n",
    "\n",
    "In this section, we will view the sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e34ab734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns of BIM file:\n",
      "Index([0, 1, 2, 3, 4, 5], dtype='int64')\n",
      "First 10 rows of BIM file:\n",
      "   0           1         2       3  4  5\n",
      "0  1   rs3131962  0.490722  756604  A  G\n",
      "1  1  rs12562034  0.495714  768448  0  0\n",
      "2  1   rs4040617  0.500708  779322  G  A\n",
      "3  1  rs79373928  0.587220  801536  G  T\n",
      "4  1  rs11240779  0.620827  808631  G  A\n",
      "Columns of FAM file:\n",
      "Index([0, 1, 2, 3, 4, 5], dtype='int64')\n",
      "First 10 rows of FAM file:\n",
      "         0        1  2  3  4  5\n",
      "0  HG00096  HG00096  0  0  1 -9\n",
      "1  HG00097  HG00097  0  0  2 -9\n",
      "2  HG00099  HG00099  0  0  2 -9\n",
      "3  HG00100  HG00100  0  0  2 -9\n",
      "4  HG00101  HG00101  0  0  1 -9\n",
      "Columns of COV file:\n",
      "Index(['FID', 'IID', 'Sex'], dtype='object')\n",
      "First 10 rows of COV file:\n",
      "       FID      IID  Sex\n",
      "0  HG00096  HG00096    1\n",
      "1  HG00097  HG00097    2\n",
      "2  HG00099  HG00099    2\n",
      "3  HG00100  HG00100    2\n",
      "4  HG00101  HG00101    1\n",
      "Columns of Height file:\n",
      "Index(['FID', 'IID', 'Height'], dtype='object')\n",
      "First 10 rows of Height file:\n",
      "       FID      IID      Height\n",
      "0  HG00096  HG00096  169.132169\n",
      "1  HG00097  HG00097  171.256259\n",
      "2  HG00099  HG00099  171.534380\n",
      "3  HG00101  HG00101  169.850176\n",
      "4  HG00102  HG00102  172.788361\n",
      "Columns of GWAS file:\n",
      "Index(['CHR', 'BP', 'SNP', 'A1', 'A2', 'N', 'SE', 'P', 'OR', 'INFO', 'MAF'], dtype='object')\n",
      "First 10 rows of GWAS file:\n",
      "   CHR      BP         SNP A1 A2       N        SE         P        OR  \\\n",
      "0    1  756604   rs3131962  A  G  388028  0.003017  0.483171  0.997887   \n",
      "1    1  768448  rs12562034  A  G  388028  0.003295  0.834808  1.000687   \n",
      "2    1  779322   rs4040617  G  A  388028  0.003033  0.428970  0.997604   \n",
      "3    1  801536  rs79373928  G  T  388028  0.008413  0.808999  1.002036   \n",
      "4    1  808631  rs11240779  G  A  388028  0.002428  0.590265  1.001308   \n",
      "\n",
      "       INFO       MAF  \n",
      "0  0.890558  0.369390  \n",
      "1  0.895894  0.336846  \n",
      "2  0.897508  0.377368  \n",
      "3  0.908963  0.483212  \n",
      "4  0.893213  0.450410  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "\n",
    "# Set the directory where the files are located\n",
    "filedirec = \"SampleData1\"\n",
    "\n",
    "# Define file paths for different data files\n",
    "BED = filedirec + os.sep + filedirec\n",
    "BIM = filedirec + os.sep + filedirec+\".bim\"\n",
    "FAM = filedirec + os.sep + filedirec+\".fam\"\n",
    "COV = filedirec + os.sep + filedirec+\".cov\"\n",
    "Height = filedirec + os.sep + filedirec+\".height\"\n",
    "GWAS = filedirec + os.sep + filedirec+\".gz\"\n",
    "\n",
    "# Read the first 10 rows of the BED file (matrix, cannot be viewed directly)\n",
    "# This is a placeholder comment since viewing a BED file is not applicable in this context\n",
    "#https://en.wikipedia.org/wiki/BED_(file_format)\n",
    "\n",
    "# Read the first 10 rows of the BIM file (PLINK map file)\n",
    "temp = pd.read_csv(BIM, sep=\"\\s+\", header=None, nrows=10)\n",
    "print(\"Columns of BIM file:\")\n",
    "print(temp.columns)\n",
    "print(\"First 10 rows of BIM file:\")\n",
    "print(temp.head())\n",
    "\n",
    "# Read the first 10 rows of the FAM file (PLINK pedigree file)\n",
    "temp = pd.read_csv(FAM, sep=\"\\s+\", header=None, nrows=10)\n",
    "print(\"Columns of FAM file:\")\n",
    "print(temp.columns)\n",
    "print(\"First 10 rows of FAM file:\")\n",
    "print(temp.head())\n",
    "\n",
    "# Read the first 10 rows of the COV file (covariate information file)\n",
    "temp = pd.read_csv(COV, sep=\"\\s+\", nrows=10)\n",
    "print(\"Columns of COV file:\")\n",
    "print(temp.columns)\n",
    "print(\"First 10 rows of COV file:\")\n",
    "print(temp.head())\n",
    "\n",
    "# Read the first 10 rows of the Height file (file containing actual height phenotypes)\n",
    "temp = pd.read_csv(Height, sep=\"\\s+\", nrows=10)\n",
    "print(\"Columns of Height file:\")\n",
    "print(temp.columns)\n",
    "print(\"First 10 rows of Height file:\")\n",
    "print(temp.head())\n",
    "\n",
    "# Read the first 10 rows of the GWAS file (GWAS summary statistic file)\n",
    "temp = pd.read_csv(GWAS, sep=\"\\s+\", nrows=10)\n",
    "print(\"Columns of GWAS file:\")\n",
    "print(temp.columns)\n",
    "print(\"First 10 rows of GWAS file:\")\n",
    "print(temp.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc342808",
   "metadata": {},
   "source": [
    "## Important Note\n",
    "\n",
    "1. This notebook needs to be executed only once to download the sample data.\n",
    "2. If someone wants to use the data in a different format, ensure you follow the same directory structure.\n",
    "3. Please ensure that your data has the same number of columns and the same headers. Cheers!\n",
    "4. For continuous phenotype GWAS, the `SampleData1/SampleData1.gz` file should have BETAs, and for binary phenotypes, it should have OR instead of BETAs. If BETAs are not available, we convert OR to BETAs using `BETA = np.log(OR)` and convert BETAs to OR using `OR = np.exp(BETA)`.\n",
    "5. `import numpy as np`; `np` is the NumPy module.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff1dea0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
